{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f7430c-9ccb-4afa-8ccd-43a23de8ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "import hashlib\n",
    "import logging\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Headers for SEC API requests\n",
    "API_HEADERS = {\n",
    "    'User-Agent': 'Your Name yourname@example.com',  # Replace with your information\n",
    "    'Accept': 'application/json',\n",
    "}\n",
    "\n",
    "def ensure_directory_exists(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def get_cached_filename(url, directory):\n",
    "    return os.path.join(directory, hashlib.md5(url.encode()).hexdigest() + '.json')\n",
    "\n",
    "def download_with_cache(url, cache_dir='sec_cache', headers=None):\n",
    "    ensure_directory_exists(cache_dir)\n",
    "    cached_file = get_cached_filename(url, cache_dir)\n",
    "    \n",
    "    if os.path.exists(cached_file):\n",
    "        logging.info(f\"Loading cached file for {url}\")\n",
    "        with open(cached_file, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    \n",
    "    logging.info(f\"Downloading {url}\")\n",
    "    try:\n",
    "        if headers is None:\n",
    "            headers = API_HEADERS\n",
    "        session = requests.Session()\n",
    "        response = session.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        content = response.text\n",
    "        \n",
    "        with open(cached_file, 'w', encoding='utf-8') as file:\n",
    "            file.write(content)\n",
    "        \n",
    "        time.sleep(0.2)  # Respectful delay after a new download\n",
    "        return content\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Error downloading {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_cik(ticker):\n",
    "    ticker = ticker.upper()\n",
    "    url = \"https://www.sec.gov/include/ticker.txt\"\n",
    "    content = download_with_cache(url, 'sec_data')\n",
    "    if content:\n",
    "        for line in content.splitlines():\n",
    "            t, c = line.strip().split('\\t')\n",
    "            if t.upper() == ticker:\n",
    "                return c.zfill(10)\n",
    "    logging.error(f\"CIK not found for ticker {ticker}\")\n",
    "    return None\n",
    "\n",
    "def get_financial_data(ticker, concepts):\n",
    "    cik = get_cik(ticker)\n",
    "    if not cik:\n",
    "        logging.error(f\"Failed to get CIK for {ticker}\")\n",
    "        return None\n",
    "    \n",
    "    # Define the date 20 years ago from today\n",
    "    twenty_years_ago = datetime.datetime.now() - datetime.timedelta(days=365 * 20)\n",
    "    twenty_years_ago_str = twenty_years_ago.strftime('%Y-%m-%d')\n",
    "    \n",
    "    financial_data = {}\n",
    "    for concept in concepts:\n",
    "        url = f\"https://data.sec.gov/api/xbrl/companyconcept/CIK{cik}/us-gaap/{concept}.json\"\n",
    "        content = download_with_cache(url, cache_dir='sec_data', headers=API_HEADERS)\n",
    "        if not content:\n",
    "            logging.error(f\"Failed to get data for {ticker} and concept {concept}\")\n",
    "            continue\n",
    "        data = json.loads(content)\n",
    "        concept_data = []\n",
    "        for unit in data.get('units', {}):\n",
    "            for fact in data['units'][unit]:\n",
    "                # Filter by date\n",
    "                fact_end_date = fact.get('end')\n",
    "                if fact_end_date and fact_end_date >= twenty_years_ago_str:\n",
    "                    concept_data.append({\n",
    "                        'date': fact_end_date,\n",
    "                        'value': fact.get('val'),\n",
    "                        'unit': unit,\n",
    "                        'concept': concept,\n",
    "                        'form': fact.get('form'),\n",
    "                        'filed': fact.get('filed'),\n",
    "                        'fy': fact.get('fy'),\n",
    "                        'fp': fact.get('fp'),\n",
    "                    })\n",
    "        # Sort the list by date in descending order\n",
    "        concept_data.sort(key=lambda x: x['date'], reverse=True)\n",
    "        financial_data[concept] = concept_data\n",
    "    return financial_data\n",
    "\n",
    "def save_financial_data_to_csv(ticker, financial_data, concepts):\n",
    "    cik = get_cik(ticker)\n",
    "    if not cik:\n",
    "        logging.error(f\"Failed to get CIK for {ticker}\")\n",
    "        return None\n",
    "    \n",
    "    # Create 'fundamentals' folder if it doesn't exist\n",
    "    ensure_directory_exists('fundamentals')\n",
    "    \n",
    "    # Collect all dates\n",
    "    all_dates = set()\n",
    "    for concept in financial_data:\n",
    "        for item in financial_data[concept]:\n",
    "            all_dates.add(item['date'])\n",
    "    all_dates = sorted(all_dates, reverse=True)\n",
    "    \n",
    "    # Build rows\n",
    "    rows = []\n",
    "    for date in all_dates:\n",
    "        row = {'date': date}\n",
    "        for concept in concepts:\n",
    "            # Find the value for this date\n",
    "            value = None\n",
    "            unit = None\n",
    "            form = None\n",
    "            filed = None\n",
    "            fy = None\n",
    "            fp = None\n",
    "            for item in financial_data.get(concept, []):\n",
    "                if item['date'] == date:\n",
    "                    value = item['value']\n",
    "                    unit = item['unit']\n",
    "                    form = item['form']\n",
    "                    filed = item['filed']\n",
    "                    fy = item['fy']\n",
    "                    fp = item['fp']\n",
    "                    break\n",
    "            row[concept] = value\n",
    "            # Include unit for each concept\n",
    "            row[f'{concept}_unit'] = unit\n",
    "        # Include additional metadata (only if available)\n",
    "        row['form'] = form\n",
    "        row['filed'] = filed\n",
    "        row['fy'] = fy\n",
    "        row['fp'] = fp\n",
    "        rows.append(row)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    # Save to CSV\n",
    "    filename = f\"fundamentals/{ticker.lower()}-{cik}-EPS.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    logging.info(f\"Saved financial data to {filename}\")\n",
    "    return filename\n",
    "\n",
    "# Read the IWM components file\n",
    "iwm_df = pd.read_csv('data/IWM_Components.txt', sep='\\t')\n",
    "\n",
    "# Save the IWM components to a CSV file\n",
    "iwm_df.to_csv('data/iwm_components.csv', index=False)\n",
    "logging.info(\"Saved IWM components to data/iwm_components.csv\")\n",
    "\n",
    "# Extract the list of tickers\n",
    "tickers = iwm_df['Ticker'].tolist()\n",
    "\n",
    "# Define the financial concepts to fetch\n",
    "concepts = [\n",
    "    'EarningsPerShareBasic',\n",
    "    'EarningsPerShareDiluted',\n",
    "    'NetIncomeLoss',\n",
    "    'OperatingIncomeLoss',\n",
    "    'GrossProfit',\n",
    "    'Revenues'  # Also known as SalesRevenueNet for some companies\n",
    "]\n",
    "\n",
    "# Create 'fundamentals' folder if it doesn't exist\n",
    "ensure_directory_exists('fundamentals')\n",
    "\n",
    "# Iterate over tickers\n",
    "for ticker in tickers:\n",
    "    logging.info(f\"Processing {ticker}\")\n",
    "    try:\n",
    "        financial_data = get_financial_data(ticker, concepts)\n",
    "        if financial_data:\n",
    "            filename = save_financial_data_to_csv(ticker, financial_data, concepts)\n",
    "            logging.info(f\"Financial data for {ticker} saved to {filename}\")\n",
    "        else:\n",
    "            logging.warning(f\"No financial data found for {ticker}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred while processing {ticker}: {e}\")\n",
    "    # Respectful delay between tickers\n",
    "    time.sleep(0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
