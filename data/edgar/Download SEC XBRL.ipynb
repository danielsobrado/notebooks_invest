{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ef245e-f936-480b-bf4e-c1af00f4471a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import hashlib\n",
    "from urllib.parse import urljoin\n",
    "import logging\n",
    "import shutil\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76064fe-4c91-4943-be49-f464fead30f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "HTML_HEADERS = {\n",
    "    'User-Agent': 'Your Name yourname@example.com',\n",
    "    'Accept-Encoding': 'gzip, deflate',\n",
    "    'Host': 'www.sec.gov'\n",
    "}\n",
    "\n",
    "XML_HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "    'Cache-Control': 'max-age=0',\n",
    "    'DNT': '1',\n",
    "    'Sec-Ch-Ua': '\"Chromium\";v=\"128\", \"Not;A=Brand\";v=\"24\", \"Google Chrome\";v=\"128\"',\n",
    "    'Sec-Ch-Ua-Mobile': '?0',\n",
    "    'Sec-Ch-Ua-Platform': '\"Windows\"',\n",
    "    'Sec-Fetch-Dest': 'document',\n",
    "    'Sec-Fetch-Mode': 'navigate',\n",
    "    'Sec-Fetch-Site': 'none',\n",
    "    'Sec-Fetch-User': '?1',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "}\n",
    "\n",
    "def ensure_directory_exists(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def get_cached_filename(url, directory):\n",
    "    return os.path.join(directory, hashlib.md5(url.encode()).hexdigest() + '.xml')\n",
    "\n",
    "def download_with_cache(url, cache_dir='sec_cache', is_xml=False):\n",
    "    ensure_directory_exists(cache_dir)\n",
    "    cached_file = get_cached_filename(url, cache_dir)\n",
    "    \n",
    "    if os.path.exists(cached_file):\n",
    "        logging.info(f\"Loading cached file for {url}\")\n",
    "        with open(cached_file, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    \n",
    "    logging.info(f\"Downloading {url}\")\n",
    "    try:\n",
    "        headers = XML_HEADERS if is_xml else HTML_HEADERS\n",
    "        session = requests.Session()\n",
    "        response = session.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        content = response.text\n",
    "        \n",
    "        with open(cached_file, 'w', encoding='utf-8') as file:\n",
    "            file.write(content)\n",
    "        \n",
    "        time.sleep(1)  # Respectful delay after a new download\n",
    "        return content\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Error downloading {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_cik(ticker):\n",
    "    ticker = ticker.upper()\n",
    "    url = \"https://www.sec.gov/include/ticker.txt\"\n",
    "    content = download_with_cache(url, 'sec_data')\n",
    "    if content:\n",
    "        for line in content.splitlines():\n",
    "            t, c = line.strip().split('\\t')\n",
    "            if t.upper() == ticker:\n",
    "                return c.zfill(10)\n",
    "    logging.error(f\"CIK not found for ticker {ticker}\")\n",
    "    return None\n",
    "\n",
    "def get_filings_url(cik, filing_type):\n",
    "    return f\"https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={cik}&type={filing_type}&dateb=&owner=exclude&count=40\"\n",
    "\n",
    "def get_xml_url(index_url):\n",
    "    content = download_with_cache(index_url)\n",
    "    if not content:\n",
    "        return None, None\n",
    "    \n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    for row in soup.find_all('tr'):\n",
    "        cells = row.find_all('td')\n",
    "        if len(cells) >= 3 and 'XBRL INSTANCE DOCUMENT' in cells[1].text:\n",
    "            link = cells[2].find('a')\n",
    "            if link and link.has_attr('href'):\n",
    "                return urljoin(\"https://www.sec.gov\", link['href']), index_url\n",
    "    \n",
    "    logging.warning(f\"No XBRL instance document found in {index_url}\")\n",
    "    return None, None\n",
    "\n",
    "def get_accession_number(url):\n",
    "    logging.debug(f\"Attempting to extract accession number from URL: {url}\")\n",
    "    match = re.search(r'/(\\d{10}-\\d{2}-\\d{6})', url)\n",
    "    if match:\n",
    "        accession_number = match.group(1)\n",
    "        logging.debug(f\"Extracted accession number: {accession_number}\")\n",
    "        return accession_number\n",
    "    logging.debug(\"Failed to extract accession number\")\n",
    "    return None\n",
    "    \n",
    "def download_xml(ticker, filing_type='10-Q', num_filings=5):\n",
    "    cik = get_cik(ticker)\n",
    "    if not cik:\n",
    "        logging.error(f\"Failed to get CIK for {ticker}\")\n",
    "        return []\n",
    "\n",
    "    filings_url = get_filings_url(cik, filing_type)\n",
    "    content = download_with_cache(filings_url)\n",
    "    if not content:\n",
    "        logging.error(f\"Failed to get filings for {ticker}\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    filing_links = []\n",
    "    for link in soup.find_all('a', href=True):\n",
    "        if 'Archives' in link['href'] and '/data/' in link['href']:\n",
    "            filing_links.append(urljoin(\"https://www.sec.gov\", link['href']))\n",
    "    \n",
    "    if not filing_links:\n",
    "        logging.error(f\"No filing links found for {ticker}\")\n",
    "        return []\n",
    "\n",
    "    xml_files = []\n",
    "    for index_url in filing_links[:num_filings]:\n",
    "        xml_url, index_url = get_xml_url(index_url)\n",
    "        if xml_url:\n",
    "            xml_content = download_with_cache(xml_url, f'xml_cache_{ticker}', is_xml=True)\n",
    "            if xml_content:\n",
    "                cached_filename = get_cached_filename(xml_url, f'xml_cache_{ticker}')\n",
    "                xml_files.append((cached_filename, xml_url, index_url))\n",
    "                logging.debug(f\"Added file: {cached_filename}, XML URL: {xml_url}, Index URL: {index_url}\")\n",
    "            else:\n",
    "                logging.error(f\"Failed to download XML from {xml_url}\")\n",
    "        else:\n",
    "            logging.warning(f\"No XML URL found for {index_url}\")\n",
    "    \n",
    "    return xml_files\n",
    "\n",
    "def rename_and_store_xml_files(xml_files, ticker, destination_folder='xbrls'):\n",
    "    ensure_directory_exists(destination_folder)\n",
    "    renamed_files = []\n",
    "\n",
    "    for cached_file, xml_url, index_url in xml_files:\n",
    "        logging.debug(f\"Processing file: {cached_file}\")\n",
    "        full_accession_number = get_accession_number(index_url)\n",
    "        if full_accession_number:\n",
    "            cik, unique_part = full_accession_number.split('-', 1)\n",
    "            logging.debug(f\"CIK: {cik}, Unique part: {unique_part}\")\n",
    "            \n",
    "            date_match = re.search(r'-(\\d{8})[-_]', xml_url)\n",
    "            date = date_match.group(1) if date_match else \"unknown_date\"\n",
    "            logging.debug(f\"Extracted date: {date}\")\n",
    "            \n",
    "            new_filename = f\"{ticker.lower()}-{cik}-{unique_part}-{date}.xml\"\n",
    "            new_filepath = os.path.join(destination_folder, new_filename)\n",
    "            logging.debug(f\"New filepath: {new_filepath}\")\n",
    "            \n",
    "            try:\n",
    "                shutil.copy2(cached_file, new_filepath)\n",
    "                renamed_files.append(new_filepath)\n",
    "                logging.info(f\"Stored {new_filepath}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to copy file: {e}\")\n",
    "        else:\n",
    "            logging.warning(f\"Could not extract accession number for {index_url}\")\n",
    "\n",
    "    return renamed_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e6fad4-3efb-4a40-bc1c-367652328974",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-21 06:59:27,845 - INFO - Loading cached file for https://www.sec.gov/include/ticker.txt\n",
      "2024-09-21 06:59:27,846 - INFO - Loading cached file for https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=0000320193&type=10-Q&dateb=&owner=exclude&count=40\n",
      "2024-09-21 06:59:27,887 - INFO - Loading cached file for https://www.sec.gov/Archives/edgar/data/320193/000032019324000081/0000320193-24-000081-index.htm\n",
      "2024-09-21 06:59:27,890 - INFO - Loading cached file for https://www.sec.gov/Archives/edgar/data/320193/000032019324000081/aapl-20240629_htm.xml\n",
      "2024-09-21 06:59:27,892 - INFO - Loading cached file for https://www.sec.gov/Archives/edgar/data/320193/000032019324000069/0000320193-24-000069-index.htm\n",
      "2024-09-21 06:59:27,896 - INFO - Loading cached file for https://www.sec.gov/Archives/edgar/data/320193/000032019324000069/aapl-20240330_htm.xml\n",
      "2024-09-21 06:59:27,897 - INFO - Loading cached file for https://www.sec.gov/Archives/edgar/data/320193/000032019324000006/0000320193-24-000006-index.htm\n",
      "2024-09-21 06:59:27,901 - INFO - Loading cached file for https://www.sec.gov/Archives/edgar/data/320193/000032019324000006/aapl-20231230_htm.xml\n",
      "2024-09-21 06:59:27,902 - INFO - Loading cached file for https://www.sec.gov/Archives/edgar/data/320193/000032019323000077/0000320193-23-000077-index.htm\n",
      "2024-09-21 06:59:27,907 - INFO - Loading cached file for https://www.sec.gov/Archives/edgar/data/320193/000032019323000077/aapl-20230701_htm.xml\n",
      "2024-09-21 06:59:27,907 - INFO - Loading cached file for https://www.sec.gov/Archives/edgar/data/320193/000032019323000064/0000320193-23-000064-index.htm\n",
      "2024-09-21 06:59:27,911 - INFO - Loading cached file for https://www.sec.gov/Archives/edgar/data/320193/000032019323000064/aapl-20230401_htm.xml\n",
      "2024-09-21 06:59:27,914 - INFO - Stored xbrls/aapl-0000320193-24-000081-20240629.xml\n",
      "2024-09-21 06:59:27,915 - INFO - Stored xbrls/aapl-0000320193-24-000069-20240330.xml\n",
      "2024-09-21 06:59:27,916 - INFO - Stored xbrls/aapl-0000320193-24-000006-20231230.xml\n",
      "2024-09-21 06:59:27,917 - INFO - Stored xbrls/aapl-0000320193-23-000077-20230701.xml\n",
      "2024-09-21 06:59:27,919 - INFO - Stored xbrls/aapl-0000320193-23-000064-20230401.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded XML files for AAPL:\n",
      "File: xml_cache_AAPL/cfdd4f144c3320fc781346b8b99caf59.xml\n",
      "XML URL: https://www.sec.gov/Archives/edgar/data/320193/000032019324000081/aapl-20240629_htm.xml\n",
      "Index URL: https://www.sec.gov/Archives/edgar/data/320193/000032019324000081/0000320193-24-000081-index.htm\n",
      "\n",
      "File: xml_cache_AAPL/2da07f5a9a13e809f11888d987a3babd.xml\n",
      "XML URL: https://www.sec.gov/Archives/edgar/data/320193/000032019324000069/aapl-20240330_htm.xml\n",
      "Index URL: https://www.sec.gov/Archives/edgar/data/320193/000032019324000069/0000320193-24-000069-index.htm\n",
      "\n",
      "File: xml_cache_AAPL/6efe51076e8ee7b5fa84035d406d202c.xml\n",
      "XML URL: https://www.sec.gov/Archives/edgar/data/320193/000032019324000006/aapl-20231230_htm.xml\n",
      "Index URL: https://www.sec.gov/Archives/edgar/data/320193/000032019324000006/0000320193-24-000006-index.htm\n",
      "\n",
      "File: xml_cache_AAPL/6c906f55166e3152702067fdac2ab7e4.xml\n",
      "XML URL: https://www.sec.gov/Archives/edgar/data/320193/000032019323000077/aapl-20230701_htm.xml\n",
      "Index URL: https://www.sec.gov/Archives/edgar/data/320193/000032019323000077/0000320193-23-000077-index.htm\n",
      "\n",
      "File: xml_cache_AAPL/07c35f55deaa310117deeea6e98a3560.xml\n",
      "XML URL: https://www.sec.gov/Archives/edgar/data/320193/000032019323000064/aapl-20230401_htm.xml\n",
      "Index URL: https://www.sec.gov/Archives/edgar/data/320193/000032019323000064/0000320193-23-000064-index.htm\n",
      "\n",
      "\n",
      "Renamed and stored XML files:\n",
      "xbrls/aapl-0000320193-24-000081-20240629.xml\n",
      "xbrls/aapl-0000320193-24-000069-20240330.xml\n",
      "xbrls/aapl-0000320193-24-000006-20231230.xml\n",
      "xbrls/aapl-0000320193-23-000077-20230701.xml\n",
      "xbrls/aapl-0000320193-23-000064-20230401.xml\n"
     ]
    }
   ],
   "source": [
    "ticker = \"AAPL\"\n",
    "form_type = \"10-Q\"\n",
    "num_filings = 5\n",
    "\n",
    "xml_files = download_xml(ticker, form_type, num_filings)\n",
    "print(f\"Downloaded XML files for {ticker}:\")\n",
    "for file, xml_url, index_url in xml_files:\n",
    "    print(f\"File: {file}\")\n",
    "    print(f\"XML URL: {xml_url}\")\n",
    "    print(f\"Index URL: {index_url}\")\n",
    "    print()\n",
    "\n",
    "renamed_files = rename_and_store_xml_files(xml_files, ticker)\n",
    "print(f\"\\nRenamed and stored XML files:\")\n",
    "for file in renamed_files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e187d8-4295-44a8-97f9-ce4dd3b61b95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
